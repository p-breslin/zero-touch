import os
import logging
import asyncio
from typing import Any
from dotenv import load_dotenv

from agno.workflow import Workflow
from agno.agent import RunResponse, RunEvent

from agno.knowledge.agent import AgentKnowledge
from agno.embedder.openai import OpenAIEmbedder
from agno.vectordb.chroma.chromadb import ChromaDb

from src.paths import DATA_DIR
from agents.agent_builder import build_agent
from utils.logging_setup import setup_logging
from services.create_engine import create_db_engine
from utils.helpers import validate_response, load_yaml
from models import SQLPlan, KBInfo, SQLQueries


load_dotenv()
setup_logging()
log = logging.getLogger(__name__)


class Pipeline(Workflow):
    """
    An Orchestrator Workflow to manage the inference process.
    """

    knowledge_base: AgentKnowledge
    db_engine: Any

    def __init__(self, **workflow_kwargs: Any):
        super().__init__(**workflow_kwargs)

        # Set up ChromaDB source for the Knowledge Base
        db_path = str(DATA_DIR / "ChromaDB")
        embedding_model = os.getenv("EMBEDDING_MODEL")
        embedder = OpenAIEmbedder(id=embedding_model, dimensions=3072)

        chromadb_collection_name = os.getenv("CHROMADB_COLLECTION")
        chromadb_instance = ChromaDb(
            collection=chromadb_collection_name,
            path=db_path,
            persistent_client=True,
            embedder=embedder,
        )
        self.knowledge_base = AgentKnowledge(
            vector_db=chromadb_instance, num_documents=10
        )

        # Set up the SQL database engine
        self.db_engine = create_db_engine()
        log.info(
            f"Workflow '{self.name or 'Pipeline'}' initialized with session_id: {self.session_id}"
        )

    def create_agent(self, key, knowledge=False):
        kb = self.knowledge_base if knowledge else None
        agent = build_agent(
            agent_key=key,
            db_engine=self.db_engine,
            knowledge_base=kb,
        )
        log.info(f"Agent '{agent.name}' built.")
        return agent

    def process_response(self, response, model, agent_name):
        try:
            structured_content = validate_response(
                response.content, model, savefile=agent_name
            )
            log.info(f"{agent_name} response validated.")
            return structured_content
        except Exception as e:
            log.exception(f"Validation error: {response.content}: {e}")
            return None

    async def arun(self) -> RunResponse | None:
        log.info(
            f"Workflow '{self.name}' run method started. Session ID: {self.session_id}, Run ID: {self.run_id}"
        )

        # Load queries
        queries = load_yaml("queries")

        # --- 1. Knowledge Base Agent ---
        log.info("Invoking KnowledgeBase_Agent...")
        kb_agent = self.create_agent("KnowledgeBase_Agent", knowledge=True)
        kb_query = queries.get("knowledgebase_query")

        kb_response: RunResponse = kb_agent.run(kb_query)
        schema_info: KBInfo | None = self.process_response(
            kb_response, KBInfo, kb_agent.name
        )
        if not schema_info:
            log.error("KnowledgeBase_Agent failed. Halting.")
            yield RunResponse(
                content="Error: KnowledgeBase_Agent failed.", run_id=self.run_id
            )
        log.info("Schema information retrieved successfully.")
        self.session_state["knowledgebase_info"] = schema_info.model_dump()

        # --- 2. Planner Agent ---
        log.info("Invoking Planner_Agent...")
        planner_agent = self.create_agent("Planner_Agent")
        planner_query_template = queries.get("planner_query")

        # Prepare input
        planner_query = planner_query_template.format(
            schema_info=schema_info.model_dump_json(indent=2)
        )
        planner_response: RunResponse = planner_agent.run(planner_query)
        sql_plan: SQLPlan | None = self.process_response(
            planner_response, SQLPlan, planner_agent.name
        )

        if not sql_plan:
            log.error("Planner_Agent failed to produce a valid SQLPlan.")
            yield RunResponse(
                content="Error: Planner_Agent failed.",
                run_id=self.run_id,
                session_id=self.session_id,
            )

        # Store the generated plan in session_state
        self.session_state["sql_plan"] = sql_plan.model_dump()
        log.info(
            f"SQLPlan generated by {planner_agent.name} and stored in session_state."
        )
        log.debug(f"Generated SQLPlan: \n{sql_plan.model_dump_json(indent=2)}")

        # --- 3. SQL Constructor Agent ---
        queries = load_yaml("queries")
        constructor_query_template = queries.get("sql_constructor_query")
        constructor_query = constructor_query_template.format(
            sql_plan=sql_plan.model_dump_json()
        )

        sql_constructor_agent = self.create_agent("SQL_Constructor_Agent")
        constructor_response: RunResponse = await sql_constructor_agent.arun(
            constructor_query
        )
        sql_queries = self.process_response(
            constructor_response, SQLQueries, sql_constructor_agent.name
        )
        self.session_state["sql_queries"] = sql_queries.model_dump()
        log.info(f"SQLQueries generated by {sql_constructor_agent.name} and stored.")

        yield RunResponse(
            run_id=self.run_id,
            session_id=self.session_id,
            content=f"Phase Complete. Generated {len(sql_queries.queries)} SQL queries. Plan Summary: {sql_queries.plan_summary}",
            event="test",
        )


if __name__ == "__main__":
    from agno.storage.sqlite import SqliteStorage
    from agno.utils.pprint import pprint_run_response

    storage_db_file = str(DATA_DIR / "orchestrator_main_session_storage.db")
    workflow_storage = SqliteStorage(
        table_name="orchestrator_sessions",
        db_file=storage_db_file,
        auto_upgrade_schema=True,
    )

    test_session_id = f"phase_test_{os.urandom(4).hex()}"

    log.info(f"--- Starting Workflow (Session: {test_session_id}) ---")

    orchestrator = Pipeline(
        name="MainOrchestrator",
        session_id=test_session_id,
        storage=workflow_storage,
        debug_mode=True,
    )

    async def main_run():
        # Iterate if multiple yields
        async for response_chunk in orchestrator.arun():
            pprint_run_response(response_chunk, markdown=False)
            if response_chunk.content and "Error:" not in str(response_chunk.content):
                log.info("Phase 1.2a intermediate step successful.")
            elif response_chunk.content and "Error:" in str(response_chunk.content):
                log.error(
                    f"Workflow run encountered an error: {response_chunk.content}"
                )
                return  # Stop on first error for this test
        log.info(
            "Phase 1.2a (SQL Constructor Test) completed successfully. Check logs and session state for 'executable_sql_queries'."
        )

    asyncio.run(main_run())
    log.info(f"Full test complete for session {test_session_id}.")
